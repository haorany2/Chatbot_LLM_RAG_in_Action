{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import ConversationalChatAgent, AgentExecutor\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict\n",
    "import boto3\n",
    "\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with LLM and RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A book and movie assistant chatbot using Python, LangChain, embedding-based retrieval strategies, and OpenAI's GPT-3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Deploy LLM  endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Retrieve the OpenAI API key and temperature from environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"env.txt\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_TEMPERATURE = float(os.getenv('OPENAI_TEMPERATURE'))\n",
    "HUGGING_FACE_TOKEN = os.getenv('HUGGING_FACE_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hub['HUGGING_FACE_HUB_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"My name is Clara and I am a wedding photographer based in the heart of Europe, having grown up in England and studied in France, I've developed a love for capturing the beauty in a mix of cultures and languages.\\nMy approach to photography is simple: I believe in telling a story through images. I capture the raw emotions, the laughter, the tears and the unforgettable moments of your special day. From the romantic countryside settings to the urban cityscapes, I find beauty in every corner and bring it to life with my lens.\\n\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "\t'HUGGING_FACE_HUB_TOKEN': HUGGING_FACE_TOKEN\n",
    "}\n",
    "\n",
    "#assert hub['HUGGING_FACE_HUB_TOKEN'] != '<REPLACE WITH YOUR TOKEN>', \"You have to provide a token.\"\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"2.0.2\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.2xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "  )\n",
    "  \n",
    "# send request\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"My name is Clara and I am\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|begine_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are an intent classifier who identify intent of a question from three topics: movies, books and others. Only return the intent<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "recommend me a book?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\"book\"\n"
     ]
    }
   ],
   "source": [
    "test_prompt = f\"\"\"\n",
    "<|begine_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are an intent classifier who identify intent of a question from three topics: movies, books and others. Only return the intent<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "recommend me a book?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = predictor.predict({\"inputs\": test_prompt})\n",
    "# response = predictor.predict({\n",
    "# \t\"inputs\": \"You are an intent classifier. There are three topics: movies, books and others. Now identify the intent of this question into one of the topics, 'recommend me a movie'. Please return only one word\",\n",
    "# })\n",
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Preparation of the Corpus\n",
    "- The book corpus is based on the [CMU Book Summary Corpus](https://www.kaggle.com/datasets/ymaricar/cmu-book-summary-dataset).\n",
    "- The movie corpus is based on the [CMU Movie Summary Corpus](https://www.cs.cmu.edu/~ark/personas/).\n",
    "- For simplicity, I've already processed and saved the corpus snippets into **data/BookSummaries/book.json** and **data/MovieSummaries/movie.json**. If you prefer, you can download the original corpus and parse it yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Step 2 Vector Space\n",
    "- Embedding-Based Retrieval: LangChain supports various retrieval strategies. If LangChain's built-in retrieval mechanisms do not mean your embedding-based retrieval requirement, you can integrate LlamaIndex or a similar tool that can create and query embeddings of your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/custom_python/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Creating vector space:  98%|█████████▊| 98/100 [01:11<00:01,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vector space to data/book_vector_store...\n",
      "Finished!\n",
      "Lodaing vector space from data/book_vector_store\n",
      "[Document(page_content='The Hobbit J. R. R. Tolkien 1937  Gandalf tricks Bilbo into hosting a party for Thorin and his band of dwarves, who sing of reclaiming the Lonely Mountain and its vast treasure from the dragon Smaug. When the music ends, Gandalf unveils a map showing a secret door into the Mountain and proposes that the dumbfounded Bilbo serve as the expedition\\'s \"burglar\". The dwarves ridicule the idea, but Bilbo, indignant, joins despite himself. The group travel into the wild, where Gandalf saves the company from trolls and leads them to Rivendell, where Elrond reveals more secrets from the map. Passing over the Misty Mountains, they are caught by goblins and driven deep underground. Although Gandalf rescues them, Bilbo gets separated from the others as they flee the goblins. Lost in the goblin tunnels, he stumbles across a mysterious ring and then encounters Gollum, who engages him in a game of riddles. As a reward for solving all riddles Gollum will show him the path out of the tunnels, but if', metadata={'id': '30292', 'title': 'The Hobbit', 'author': 'J. R. R. Tolkien', 'publication_date': '1937', 'genres': [\"Children's literature\", 'Juvenile fantasy', 'Adventure novel', 'Speculative fiction', 'Fantasy', 'Fiction'], 'description': ' Gandalf tricks Bilbo into hosting a party for Thorin and his band of dwarves, who sing of reclaiming the Lonely Mountain and its vast treasure from the dragon Smaug. When the music ends, Gandalf unveils a map showing a secret door into the Mountain and proposes that the dumbfounded Bilbo serve as the expedition\\'s \"burglar\". The dwarves ridicule the idea, but Bilbo, indignant, joins despite himself. The group travel into the wild, where Gandalf saves the company from trolls and leads them to Rivendell, where Elrond reveals more secrets from the map. Passing over the Misty Mountains, they are caught by goblins and driven deep underground. Although Gandalf rescues them, Bilbo gets separated from the others as they flee the goblins. Lost in the goblin tunnels, he stumbles across a mysterious ring and then encounters Gollum, who engages him in a game of riddles. As a reward for solving all riddles Gollum will show him the path out of the tunnels, but if Bilbo fails, his life will be forfeit. With the help of the ring, which confers invisibility, Bilbo escapes and rejoins the dwarves, improving his reputation with them. The goblins and Wargs give chase but the company are saved by eagles before resting in the house of Beorn. The company enters the black forest of Mirkwood without Gandalf. In Mirkwood, Bilbo first saves the dwarves from giant spiders and then from the dungeons of the Wood-elves. Nearing the Lonely Mountain, the travellers are welcomed by the human inhabitants of Lake-town, who hope the dwarves will fulfil prophecies of Smaug\\'s demise. The expedition travels to the Lonely Mountain and finds the secret door; Bilbo scouts the dragon\\'s lair, stealing a great cup and learning of a weakness in Smaug\\'s armour. The enraged dragon, deducing that Lake-town has aided the intruder, sets out to destroy the town. A noble thrush who overheard Bilbo\\'s report of Smaug\\'s vulnerability reports it to Bard, who slays the dragon. When the dwarves take possession of the mountain, Bilbo finds the Arkenstone, an heirloom of Thorin\\'s dynasty, and steals it. The Wood-elves and Lake-men besiege the mountain and request compensation for their aid, reparations for Lake-town\\'s destruction, and settlement of old claims on the treasure. Thorin refuses and, having summoned his kin from the mountains of the North, reinforces his position. Bilbo tries to ransom the Arkenstone to head off a war, but Thorin is intransigent. He banishes Bilbo, and battle seems inevitable. Gandalf reappears to warn all of an approaching army of goblins and Wargs. The dwarves, men, and elves band together, but only with the timely arrival of the eagles and Beorn do they win the climactic Battle of Five Armies. Thorin is fatally wounded and reconciles with Bilbo before he dies. Bilbo accepts only a small portion of his share of the treasure, having no want or need for more, but still returns home a very wealthy hobbit.\\n'}), Document(page_content='The Lord of the Rings J. R. R. Tolkien   Long before the events of the novel, the Dark Lord Sauron forges the One Ring to dominate the other Rings of Power and corrupt those who wear them: the leaders of Men, Elves and Dwarves. He is vanquished in battle by an alliance of Elves and Men. Isildur cuts the One Ring from Sauron\\'s finger, claiming it as an heirloom for his line, and Sauron loses his physical form. When Isildur is later ambushed and killed by Orcs, the Ring is lost in the River Anduin. Over two thousand years later, the Ring is found by a river-dwelling hobbit called Déagol. His friend Sméagol immediately falls under the Ring\\'s influence and strangles Déagol to acquire it. Sméagol is banished and hides under the Misty Mountains, where the Ring extends his lifespan and transforms him over the course of hundreds of years into a twisted, corrupted creature called Gollum. He loses the Ring, his \"precious\", and, as recounted in The Hobbit, Bilbo Baggins finds it. Meanwhile,', metadata={'id': '29798', 'title': 'The Lord of the Rings', 'author': 'J. R. R. Tolkien', 'publication_date': '', 'genres': ['Adventure novel', 'Speculative fiction', 'Fantasy', 'Fiction', 'Chivalric romance', 'High fantasy'], 'description': ' Long before the events of the novel, the Dark Lord Sauron forges the One Ring to dominate the other Rings of Power and corrupt those who wear them: the leaders of Men, Elves and Dwarves. He is vanquished in battle by an alliance of Elves and Men. Isildur cuts the One Ring from Sauron\\'s finger, claiming it as an heirloom for his line, and Sauron loses his physical form. When Isildur is later ambushed and killed by Orcs, the Ring is lost in the River Anduin. Over two thousand years later, the Ring is found by a river-dwelling hobbit called Déagol. His friend Sméagol immediately falls under the Ring\\'s influence and strangles Déagol to acquire it. Sméagol is banished and hides under the Misty Mountains, where the Ring extends his lifespan and transforms him over the course of hundreds of years into a twisted, corrupted creature called Gollum. He loses the Ring, his \"precious\", and, as recounted in The Hobbit, Bilbo Baggins finds it. Meanwhile, Sauron reassumes physical form and takes back his old realm of Mordor. Gollum sets out in search of the Ring, but is captured by Sauron, who learns from him that \"Baggins\" now has it. Gollum is set loose, and Sauron, who needs the Ring to regain his full power, sends forth his powerful servants, the Nazgûl, to seize it. The novel begins in the Shire, where the Hobbit Frodo Baggins inherits the Ring from Bilbo, his cousin and guardian. Neither is aware of its origin, but Gandalf the Grey, a wizard and old friend of Bilbo, suspects the Ring\\'s identity. When he becomes certain, he strongly advises Frodo to take it away from the Shire. Frodo leaves, accompanied by his gardener and friend, Samwise (\"Sam\") Gamgee, and two cousins, Meriadoc (\"Merry\") Brandybuck and Peregrin (\"Pippin\") Took. They nearly encounter the Nazgûl while still in the Shire, but shake off pursuit by cutting through the Old Forest, where they are aided by the enigmatic Tom Bombadil, who alone is unaffected by the Ring\\'s corrupting influence. After leaving the forest, they stop in the town of Bree where they meet Aragorn, Isildur\\'s heir. He persuades them to take him on as guide and protector. They flee from Bree after narrowly escaping another assault, but the Nazgûl follow and attack them on the hill of Weathertop, wounding Frodo with a Morgul blade. Aragorn leads the hobbits toward the Elven refuge of Rivendell, while Frodo gradually succumbs to the wound. The Ringwraiths nearly overtake Frodo at the Ford of Bruinen, but flood waters summoned by Elrond, master of Rivendell, rise up and overwhelm them. Frodo recovers in Rivendell under the care of Elrond. The Council of Elrond reveals much significant history about Sauron and the Ring, as well as the news that Sauron has corrupted Gandalf\\'s fellow wizard, Saruman. The Council decides that they must destroy the Ring, but that can only be done by returning it to the flames of Mount Doom in Mordor, where it was forged. Frodo volunteers to take on this daunting task, and a \"Fellowship of the Ring\" is formed to aid him: Sam, Merry, Pippin, Aragorn, Gandalf, Gimli the Dwarf, Legolas the Elf, and the Man Boromir, son of the Ruling Steward Denethor of the realm of Gondor. After a failed attempt to cross the Misty Mountains via the pass below Caradhras, the company are forced to try a more perilous path through the Mines of Moria, where they are attacked by the Watcher in the Water before the gate. Once inside, they discover the fate of Balin and his company of Dwarves, and realize their own danger. After repulsing an attack, they are pursued by orcs and an ancient, powerful Balrog. Gandalf confronts the Balrog, but in their struggle, both fall into a deep chasm. The others escape and take refuge in the Elven forest of Lothlórien, where they are counselled by Galadriel and Celeborn. With boats and gifts from Galadriel, the company travel down the River Anduin to the hill of Amon Hen. Boromir succumbs to the lure of the Ring and attempts to take it from Frodo. Frodo escapes and determines to continue the quest alone, though Sam guesses his intent and comes along. Meanwhile, orcs sent by Saruman and Sauron kill Boromir and kidnap Merry and Pippin. After agonizing over which pair of hobbits to follow, Aragorn, Gimli and Legolas pursue the orcs bearing Merry and Pippin to Saruman. In the kingdom of Rohan, the orcs are slain by a company of the Rohirrim. Merry and Pippin escape into Fangorn Forest, where they are befriended by Treebeard, the oldest of the tree-like Ents. Aragorn, Gimli and Legolas track the hobbits to Fangorn, and encounter Gandalf, resurrected as the significantly more powerful \"Gandalf the White\" after his mutually fatal duel with the Balrog. Gandalf assures them that Merry and Pippin are safe. They ride to Edoras, the capital of Rohan, where they free Théoden, King of Rohan, from the influence of Saruman\\'s henchman Gríma Wormtongue. Théoden musters his fighting strength and rides to the ancient fortress of Helm\\'s Deep, but en route Gandalf leaves to seek help from Treebeard. Meanwhile, the Ents, roused from their customarily peaceful ways by Merry and Pippin, attack Isengard, Saruman\\'s stronghold, and trap the wizard in the tower of Orthanc. Gandalf convinces Treebeard to send an army of Huorns to Théoden\\'s aid. Gandalf and Rohirrim reinforcements arrive just in time to defeat and scatter Saruman\\'s army. The Huorns dispose of the fleeing orcs. Gandalf then parleys with Saruman at Orthanc. When Saruman rejects his offer of redemption, Gandalf strips him of his rank and most of his powers. Pippin looks into a palantír, a seeing-stone that Saruman had used to communicate with Sauron and through which he was enslaved. Gandalf rides for Minas Tirith, chief city of Gondor, taking Pippin with him. Frodo and Sam capture Gollum, who had been following them from Moria, and force him to guide them to Mordor. Finding Mordor\\'s Black Gate too well guarded to attempt, they travel instead to a secret passage Gollum knows. Torn between his loyalty to Frodo and his desire for the Ring, Gollum eventually betrays Frodo by leading him to the great spider Shelob in the tunnels of Cirith Ungol. Frodo is felled by Shelob\\'s bite, but Sam fights her off. Sam takes the Ring and leaves Frodo, believing him to be dead. When orcs find Frodo, Sam overhears them say that Frodo is only unconscious, and chases after them. Sauron unleashes a heavy assault upon Gondor. Gandalf arrives at Minas Tirith to alert Denethor of the impending attack. The city is besieged, and Denethor, driven to despair by Sauron through the use of another palantír, gives up hope and commits suicide, nearly taking his remaining son Faramir with him. With time running out, Aragorn has no choice but to take the Paths of the Dead, accompanied by Legolas and Gimli. There Aragorn raises an undead army of oath-breakers bound by an ancient curse. The ghostly army help them to defeat the Corsairs of Umbar invading southern Gondor. The forces of Gondor and Rohan break the siege of Minas Tirith. Sam rescues Frodo from the tower of Cirith Ungol, and they set out across Mordor. Meanwhile, in order to distract Sauron from his true danger, Aragorn leads the armies of Gondor and Rohan in a march on the Black Gate of Mordor. His vastly outnumbered troops fight desperately against Sauron\\'s armies. At the edge of the Cracks of Doom, Frodo is unable to resist the Ring any longer, and claims it for himself. Gollum suddenly reappears, struggles with Frodo and bites off his finger, Ring and all. Celebrating wildly, Gollum falls into the fire, taking the Ring with him. With the destruction of the One Ring, Sauron perishes, along with the Nazgûl, and his armies are thrown into such disarray that Aragorn\\'s forces emerge victorious. With the end of the War of the Ring, Aragorn is crowned Elessar, King of Arnor and Gondor, and marries his long-time love, Arwen, daughter of Elrond. Saruman escapes from Isengard and enslaves the Shire. The four hobbits, upon returning home, raise a rebellion and overthrow him. Gríma turns on Saruman and kills him, and is slain in turn by hobbit archers. The War of the Ring thus comes to its true end on Frodo\\'s very doorstep. Merry and Pippin are acclaimed heroes, while Sam marries Rosie Cotton and uses his gifts from Galadriel to help heal the Shire. Frodo, however, remains wounded in body and spirit after having borne the weight of the One Ring so long. Several years later, accompanied by Bilbo and Gandalf, he sails from the Grey Havens west over the Sea to the Undying Lands to find peace. After Rosie\\'s death, Sam gives his daughter the Red Book of Westmarch, containing the account of Bilbo\\'s adventures and the War of the Ring as witnessed by the hobbits. Sam is then said to have crossed west over the Sea himself, the last of the Ring-bearers.\\n'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating vector space:  98%|█████████▊| 98/100 [00:11<00:00,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vector space to data/movie_vector_store...\n",
      "Finished!\n",
      "Lodaing vector space from data/movie_vector_store\n",
      "[Document(page_content=\"This convinces Xi that he has reached the edge of the world, and he throws the bottle off the cliff (this scene was filmed at God's Window in Eastern Transvaal, South Africa . Xi then returns to his band and a warm welcome from his family. Adventure Action/Adventure Indie World cinema Cult Adventure Comedy Comedy Slapstick Nic De Jager Michael Thys Fanyana H. Sidumo Brian O'Shaughnessy Vera Blacker Joe Seakatsie Ken Gampu Jamie Uys Sandra Prinsloo Paddy O'Byrne Louw Verwey Marius Weyers N!xau\", metadata={'movie_id': '261237', 'title': 'The Gods Must Be Crazy', 'release_date': '1980', 'supported_languages': ['Afrikaans Language', 'English Language'], 'movie_countries': ['South Africa'], 'movie_genres_list': ['Adventure', 'Action/Adventure', 'Indie', 'World cinema', 'Cult', 'Adventure Comedy', 'Comedy', 'Slapstick'], 'movie_actor_list': ['Nic De Jager', 'Michael Thys', 'Fanyana H. Sidumo', \"Brian O'Shaughnessy\", 'Vera Blacker', 'Joe Seakatsie', 'Ken Gampu', 'Jamie Uys', 'Sandra Prinsloo', \"Paddy O'Byrne\", 'Louw Verwey', 'Marius Weyers', 'N!xau'], 'summary': 'The film is a collision of three separate stories—the journey of a Ju/\\'hoansi Bushman to the end of the earth to get rid of a Coca-Cola bottle, the romance between a bumbling scientist and a schoolteacher, and a band of guerrillas on the run. Xi and his tribe of San/Bushmen relatives are living well off the land in the Kalahari Desert. They are happy because the gods have provided plenty of everything, and no one in the tribe has unfulfilled wants. One day, a glass Coca-Cola bottle is thrown out of an aeroplane and falls to earth unbroken. Initially, this strange artifact seems to be another boon from the gods—-Xi\\'s people find many uses for it. But unlike anything that they have had before, there is only one bottle to go around. This exposes the tribe to a hitherto unknown phenomenon, property, and they soon find themselves experiencing things they never had before: jealousy, envy, anger, hatred, even violence. Since it has caused the tribe unhappiness on two occasions, Xi decides that the bottle is an evil thing and must be thrown off of the edge of the world. He sets out alone on his quest and encounters Western civilization for the first time. The film presents an interpretation of civilization as viewed through Xi\\'s perceptions. There are also plot lines about shy biologist Andrew Steyn who is studying the local animals ; the newly hired village school teacher, a former newspaper reporter named Kate Thompson; and some guerrillas led by Sam Boga, who are being pursued by government troops after an unsuccessful attempt to massacre the Cabinet of \"Barani\" and the president. Also taking a share of the limelight is Steyn\\'s Land Rover, dubbed the Antichrist  by his assistant and mechanic, M\\'pudi  . Also part of the chaos is an impudent safari tour guide named Jack Hind, who has designs on Thompson and often steals Steyn\\'s thunder. Xi happens upon a farm and, being hungry as well as oblivious to the concept of ownership, shoots a goat with a tranquilizer arrow. For this he is arrested and jailed for stealing livestock. M\\'pudi, who lived with the Bushmen for a long time and speaks Xi\\'s language, realizes that Xi will die in the alien environment of a prison cell, and he and Steyn manage to hire Xi as a tracker for the 11 remaining weeks of his prison sentence. Meanwhile, the guerrillas invade the school where Kate teaches and use her and her pupils as human shields for their escape by foot to the neighboring country and threaten to kill the children if they see one soldier. Steyn, M\\'pudi and Xi, who are unwittingly observing the local wildlife within the terrorists\\' chosen path, manage to immobilize the guerrillas as they are passing by and save Kate and the children. Steyn allows Xi to leave to continue his quest to the edge of the world, and subsequently he and Kate become romantically involved. Xi eventually finds himself at the top of a cliff with a solid layer of low-lying clouds obscuring the landscape below. This convinces Xi that he has reached the edge of the world, and he throws the bottle off the cliff (this scene was filmed at God\\'s Window in Eastern Transvaal, South Africa . Xi then returns to his band and a warm welcome from his family.'}), Document(page_content='noticing several of the buildings around him, including the cathedral and steps on which the bird woman was sitting earlier. At the bank, he is formally humiliated and sacked for causing the first run on the bank since 1773 . However, after being at a loss when ordered to give a statement, Mr. Banks invokes Mary Poppins\\' all-purpose word \"Supercalifragilisticexpialidocious!\" to tweak Mr. Dawes. He gives Dawes the tuppence, tells the old man one of Bert\\'s and Uncle Albert\\'s jokes, and raucously departs. Dawes mulls over the joke, finally \"gets it\" and floats up into the air, laughing. The next morning, the wind has changed direction, and so Mary must depart. Meanwhile, the Banks adults cannot find Mr. Banks, and fear that he might have become suicidal. However, Mr. Banks, now loving and joyful, reappears with the now-mended kite and cheerfully summons his children. The greatly relieved Mrs. Banks supplies a tail for the kite, using one of her suffragette ribbons. They all leave the', metadata={'movie_id': '77856', 'title': 'Mary Poppins', 'release_date': '1964-08-27', 'supported_languages': ['English Language'], 'movie_countries': ['United States of America'], 'movie_genres_list': [\"Children's/Family\", 'Musical', 'Fantasy', 'Comedy', 'Drama', 'Family Film', \"Children's Fantasy\"], 'movie_actor_list': ['Karen Dotrice', 'David Tomlinson', 'Dick Van Dyke', 'Julie Andrews', 'Dick Van Dyke', 'Arthur Treacher', 'Reta Shaw', 'Ed Wynn', 'Hermione Baddeley', 'Glynis Johns', 'Elsa Lanchester', 'Reginald Owen', 'Matthew Garber'], 'summary': 'The film opens with Mary Poppins  perched in a cloud high above London in spring 1910.\"... It\\'s grand to be an Englishman in 1910 / King Edward\\'s on the throne; it\\'s the age of men! ...\" George Banks\\' opening song \\'The Life I Lead\\'; King Edward VII of the United Kingdom died 6 May 1910 The action descends to Earth where Bert , a Cockney jack-of-all-trades is performing as a one-man band at a park entrance. The spectators watching him include: Ms. Persimmon , Miss Lark  and Mrs. Corry . He suddenly senses that his good friend is about to return. After the show, he speaks directly to the audience, introducing viewers first to Admiral Boom, who keeps his exterior rooftop \"Ship Shape\", by firing his cannon at 8:AM and 6:PM each day, and then to the well-to-do but troubled Banks family, headed by the cold and aloof George Banks  and the loving but highly distracted suffragette Winifred Banks . The Bankses\\' latest nanny, Katie Nanna , is quitting, exasperated after the Banks children, Jane  and Michael , have run off for the fourth time this week. Ellen, the maid , pleads with her not to leave, but Mrs. Brill, the cook , wishes her good riddance. Mrs. Banks returns home, and engages all four women in a rousing rendition of \"Sister Suffragette\", before Katie Nanna stalks out. Mr. Banks returns home from his job at the Dawes Tomes Mousley Grubbs Fidelity Fiduciary Bank, and Mrs. Banks reveals the children are missing. A policeman , arrives with the children, who ask their father to help repair their damaged kite, but he dismisses them and advertises for an authoritarian nanny-replacement. Jane and Michael draft their own advertisement asking for a fun, kind-hearted and caring person, but Mr. Banks tears up the paper and throws it in the fireplace. Unnoticed, the remains of the note float up the dark chimney. The next day, a queue of elderly and disagreeable looking candidates await at the door. However, a strong gust of wind blows the queue away and Mary Poppins floats down, held aloft by her magical umbrella, to apply. Mr. Banks is stunned to see that this calmly defiant new nanny has responded to the children\\'s ad despite the fact he destroyed it. Although Mary Poppins recites the ad, she also tells George that she is firm and will also lay down ground rules with the children. As he puzzles, Mary Poppins employs herself and begins work, saying that she will stay for a trial period of one week, before deciding if she will take a permanent position. The children face surprises of their own: Mary possesses a bottomless carpetbag, and makes contents of the children\\'s nursery come to life and tidy themselves . The trio then meet Bert, who is a close friend of Mary, in the park at work as a screever, where Mary uses one of his chalk pavement drawings as a gateway to an outing in an animated countryside. While in the drawing, the children ride a merry-go-round while Mary and Bert enjoy a stroll through the countryside, during which Bert dances at an outdoor bistro with four penguin waiters. Mary and Bert join the children on the merry-go-round, from which the horses break loose and take their riders on a trip through the countryside. As they pass by a fox hunt, Bert maneuvers to save an Irish-accented fox from the bloodhounds. Finally the quartet finds themselves in a horse race, which Mary wins. It is here that Mary first employs the nonsense word \"Supercalifragilisticexpialidocious.\" The outing is interrupted by a rainstorm, which washes away the chalk drawing and returns the travellers, drenched, to the park pavement. That evening, the children ask Mary how long she\\'ll stay with them. With a somber expression, she replies, \"I shall stay until the wind changes\". The next day, they all visit Bert\\'s jovial Uncle Albert , who floats whenever he laughs, and join him in a tea party in mid-air, though Mary finds it childish and ridiculous. They all get down, only when one had to think of \"Something Sad\", when Mary firmly says: \"It is time to go home.\" Mr. Banks grows increasingly irate with his children\\'s stories of their adventures, but Mary effortlessly inverts his attempted dismissal of her services into a plan to take his children with him to the Dawes Tomes Mousley Grubbs Fidelity Fiduciary Bank, where he is employed. On the way there, as they pass the bank, the children see \"The Bird Woman\" , of whom Mary sang to them the night before, and they want to feed the birds around her, but George will have none of it as he expresses his lack of interest in what Mary Poppins says and orders his children to \"come along\" and not mention her name for the rest of the day. Upon arriving at the bank, Mr. Dawes Jr  and Mr. Dawes Sr —Mr. Banks\\' employers—aggressively try to persuade Michael to invest his tuppence in the bank to the point of actually snatching it out of his hand without waiting for his permission. When Michael protests, the other customers misunderstand and start a run on the bank that forces the bank to suspend business. The Bank Guard  chases the children causing the children to flee and wander into the slums of the East End of London. Fortunately, they run into Bert, now employed as a chimney sweep. He takes them safely home, explaining that their father does not hate them, but that he has problems of his own, and that unlike the children, has no one to turn to but himself. At home, a departing Mrs. Banks employs Bert to clean the family\\'s chimney and mind the children. Mary Poppins arrives back from her day off and warns of the dangers of this activity, but is too late as the children are both sucked up the chimney to the roof. Bert and Mary follow them and lead a tour of the rooftops of London that concludes with a joyful dance with Bert\\'s chimney-sweep colleagues. A volley of fireworks from the Banks\\' eccentric neighbour, Admiral Boom , who mistakes them for Hottentots, orders Mr. Binnacle  to set off the fireworks which sends the entire gathering back down a different chimney, which turns out to be the Banks\\' chimney. Mr. Banks arrives home, causing the chimney sweepers to depart outside the home, and out into the street, where they disappear from view within less than half a minute. Their departure conclude the festivities. Banks angrily inquires Mary Poppins what was the meaning of this, in which Mary replies that she never explains anything. Banks then receives a phone call from work ordering him to return immediately for disciplinary action. As Mr. Banks gathers his strength, Bert points out that while Mr. Banks does need to make a living, his offspring\\'s childhood will come and go in a blink of an eye, and he needs to be there for them while he can. The Banks children approach their father to apologize, and Michael gives Mr. Banks his tuppence in the hope that it will make things all right. Banks gently accepts the offering. A somber and thoughtful Mr. Banks walks alone through the night-time streets, for the first time noticing several of the buildings around him, including the cathedral and steps on which the bird woman was sitting earlier. At the bank, he is formally humiliated and sacked for causing the first run on the bank since 1773 . However, after being at a loss when ordered to give a statement, Mr. Banks invokes Mary Poppins\\' all-purpose word \"Supercalifragilisticexpialidocious!\" to tweak Mr. Dawes. He gives Dawes the tuppence, tells the old man one of Bert\\'s and Uncle Albert\\'s jokes, and raucously departs. Dawes mulls over the joke, finally \"gets it\" and floats up into the air, laughing. The next morning, the wind has changed direction, and so Mary must depart. Meanwhile, the Banks adults cannot find Mr. Banks, and fear that he might have become suicidal. However, Mr. Banks, now loving and joyful, reappears with the now-mended kite and cheerfully summons his children. The greatly relieved Mrs. Banks supplies a tail for the kite, using one of her suffragette ribbons. They all leave the house without a backward glance as Mary Poppins watches from a window. In the park with other kite-flyers, Mr. Banks meets Mr. Dawes Jr., now in charge of the bank, who says that his father literally died laughing. Instead of being upset, the son is delighted his father died happy and re-employs Mr. Banks to fill the opening as junior partner. Her work done, Mary Poppins takes to the air with a fond farewell from Bert , telling her not to stay away too long.'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %load vector_space.py\n",
    "# vector_space.py\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name):\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        return self.embeddings\n",
    "\n",
    "class VectorSpaceManager:\n",
    "    def __init__(self, embedding_manager):\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.embeddings = self.embedding_manager.get_embeddings()\n",
    "\n",
    "    def create_vector_space(self, documents):\n",
    "        vector_store = FAISS.from_documents(self._split_docs(documents[:2]), self.embeddings)\n",
    "\n",
    "        with tqdm(total=len(documents), desc=\"Creating vector space\") as pbar:\n",
    "            batch_size = 100\n",
    "            for i in range(2, len(documents), batch_size):\n",
    "                batch_documents = documents[i:i+batch_size]\n",
    "                tempt_vector_store = FAISS.from_documents(self._split_docs(batch_documents), self.embeddings)\n",
    "                vector_store.merge_from(tempt_vector_store)\n",
    "                pbar.update(len(batch_documents))\n",
    "        #vector_store = FAISS.from_documents(self._split_docs(documents), self.embeddings)\n",
    "\n",
    "        return vector_store\n",
    "\n",
    "    def save_vector_space(self, vector_store, save_path):\n",
    "        print(f\"Saving vector space to {save_path}...\")\n",
    "        vector_store.save_local(save_path)\n",
    "        print(f\"Finished!\")\n",
    "\n",
    "    def load_vector_space(self, save_path):\n",
    "        print(f\"Lodaing vector space from {save_path}\")\n",
    "        return FAISS.load_local(save_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "    def _split_docs(self, docs: list):\n",
    "        # split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\" \", \"\\n\", \",\"],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0,\n",
    "        )\n",
    "        split_docs = text_splitter.split_documents(docs)\n",
    "        return split_docs\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, json_file_path):\n",
    "        self.json_file_path = json_file_path\n",
    "\n",
    "    def load_data(self):\n",
    "        data = json.loads(Path(self.json_file_path).read_text())\n",
    "        return data\n",
    "\n",
    "    def create_documents(self, length=None):\n",
    "        data = self.load_data()\n",
    "        if length is None:\n",
    "            length = len(data)\n",
    "        \n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=self.get_page_content(item),\n",
    "                metadata=item\n",
    "            )\n",
    "            for item in data[:length]\n",
    "        ]\n",
    "        return documents\n",
    "\n",
    "    def get_page_content(self, item):\n",
    "        raise NotImplementedError(\"Subclasses must implement get_page_content method\")\n",
    "    \n",
    "\n",
    "class BookDataLoader(DataLoader):\n",
    "    def get_page_content(self, item):\n",
    "        return f\"{item['title']} {item['author']} {item['publication_date']} {item['description']} {' '.join(item['genres'])}\"\n",
    "    \n",
    "\n",
    "class MovieDataLoader(DataLoader):\n",
    "    def get_page_content(self, item):\n",
    "        # {movie_id, title, release_date, supported_languages, movie_countries, movie_genres_list, movie_actor_list, summary}\n",
    "        # Use all the fields to create the page content\n",
    "        return f\"{item['title']} {item['release_date']} {item['summary']} {' '.join(item['movie_genres_list'])} {' '.join(item['movie_actor_list'])}\"\n",
    "\n",
    "def process_data(json_file_path, model_name, save_path, data_loader_class, length=None):\n",
    "    # Initialize the embedding manager with the chosen model\n",
    "    embedding_manager = EmbeddingManager(model_name)\n",
    "\n",
    "    # Initialize the vector space manager with the embedding manager\n",
    "    vector_space_manager = VectorSpaceManager(embedding_manager)\n",
    "\n",
    "    # Load data and create documents\n",
    "    data_loader = data_loader_class(json_file_path)\n",
    "    documents = data_loader.create_documents(length=length)\n",
    "\n",
    "    # Create and save the vector space\n",
    "    vector_store = vector_space_manager.create_vector_space(documents)\n",
    "    vector_space_manager.save_vector_space(vector_store, save_path)\n",
    "\n",
    "    # Load the vector space and perform a search\n",
    "    vector_store = vector_space_manager.load_vector_space(save_path)\n",
    "    query = \"The Hobbit\"\n",
    "    search_results = vector_store.search(query, k=2, search_type=\"similarity\")\n",
    "    print(search_results)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Book\n",
    "    json_file_path = 'data/BookSummaries/book.json'  # Replace with the actual JSON file path\n",
    "    #model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    #model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "    #model_name = \"intfloat/e5-base-v2\"\n",
    "    model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "    save_path = 'data/book_vector_store'  # Replace with the actual save path\n",
    "    process_data(json_file_path, model_name, save_path, BookDataLoader, 100)\n",
    "\n",
    "    # Movie\n",
    "    json_file_path = 'data/MovieSummaries/movie.json'  # Replace with the actual JSON file path\n",
    "    #model_name = \"intfloat/e5-base-v2\"\n",
    "    model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "    #model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    #model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "    save_path = 'data/movie_vector_store'  # Replace with the actual save path\n",
    "    process_data(json_file_path, model_name, save_path, MovieDataLoader, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 3: Chatbot Logic and User Interaction\n",
    "- User Query Handling: Design the chatbot to accept user input, which could range from specific questions about books to general requests for recommendations.\n",
    "- Query to Embedding: Convert the user query into an embedding and use the retrieval strategy to find the most relevant book summaries.\n",
    "- Interaction with GPT-3.5: Send the user query and retrieved book summaries to GPT-3.5 to generate a coherent and contextually appropriate response.\n",
    "- Response Generation: Combine the LLM's output with the retrieved information to generate a final response to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TopicClassifier:\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"\n",
    "        Initializes a TopicClassifier object.\n",
    "\n",
    "        Parameters:\n",
    "        llm (LanguageModel): The language model used for classification.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.topics = [\"movies\", \"books\", \"others\"]\n",
    "\n",
    "\n",
    "    def classify(self, query):\n",
    "        \"\"\"\n",
    "        Classifies a given query into one of the predefined topics.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to be classified.\n",
    "\n",
    "        Returns:\n",
    "        str: The classified topic.\n",
    "        \"\"\"\n",
    "        # prompt = f\"\"\"\n",
    "        # You are a content intent identifier. There are three intent for you: '{','.join(self.topics)}'. \n",
    "        # Now identify the intent of below question: {query}. Only return intent in one word.\n",
    "        # \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        <|begine_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "        You are an intent classifier who identify intent of a question from three topics: '{','.join(self.topics)}'. Only return the intent<|eot_id|>\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "        {query}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "        \"\"\"\n",
    "        # prompt = f\"Classify the following question into one of these topics: '{','.join(self.topics)}': '{query}'\"\n",
    "        response = self.llm.predict(text=prompt, max_tokens=10)\n",
    "        topic = response.split('<|end_header_id|>')[-1].strip().lower()\n",
    "        # topic = response.strip().lower()\n",
    "        return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS  \n",
    "from langchain.agents import Tool\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "class ToolManager:\n",
    "    def __init__(self, llm, movies_vector_path, books_vector_path, embeddings):\n",
    "        self.llm = llm\n",
    "        self.movies_vector_path = movies_vector_path\n",
    "        self.books_vector_path = books_vector_path\n",
    "        self.embeddings = embeddings\n",
    "        self.tools = self._initialize_tools()\n",
    "\n",
    "    def _initialize_tools(self):\n",
    "        # Load FAISS vector stores for movies and books\n",
    "        movies_vector_store = FAISS.load_local(self.movies_vector_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "        books_vector_store = FAISS.load_local(self.books_vector_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "        # Define prompt template\n",
    "        prompt_template = \"\"\"If the context is not relevant, \n",
    "        please answer the question by using your own knowledge about the topic\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "        # Initialize RetrievalQA tools with the FAISS vector stores\n",
    "        movies_qa = RetrievalQA.from_chain_type(llm=self.llm, chain_type=\"stuff\", retriever=movies_vector_store.as_retriever(search_kwargs={\"k\": 3}), chain_type_kwargs={\"prompt\": PROMPT})\n",
    "        books_qa = RetrievalQA.from_chain_type(llm=self.llm, chain_type=\"stuff\", retriever=books_vector_store.as_retriever(search_kwargs={\"k\": 3}), chain_type_kwargs={\"prompt\": PROMPT})\n",
    "\n",
    "        # Return a dictionary of tools for movies and books\n",
    "        return {\n",
    "            \"movies\": Tool(name=\"MoviesTool\", func=movies_qa.run, description=\"Retrieve movie information.\"),\n",
    "            \"books\": Tool(name=\"BooksTool\", func=books_qa.run, description=\"Retrieve book information.\")\n",
    "        }\n",
    "\n",
    "    def get_tool(self, topic):\n",
    "        return self.tools.get(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import ConversationalChatAgent, AgentExecutor\n",
    "\n",
    "class ChatAgent:\n",
    "    def __init__(self, llm, tool_manager):\n",
    "        self.llm = llm\n",
    "        self.tool_manager = tool_manager\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"input\", return_messages=True)\n",
    "        self.agent = ConversationalChatAgent.from_llm_and_tools(llm=self.llm, tools=list(self.tool_manager.tools.values()), system_message=\"You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\")\n",
    "        self.chat_agent = AgentExecutor.from_agent_and_tools(agent=self.agent, tools=list(self.tool_manager.tools.values()), verbose=True, memory=self.memory, \n",
    "                                                             handle_parsing_errors = True)\n",
    "\n",
    "    def get_response(self, query, topic_classifier):\n",
    "        \"\"\"\n",
    "        Get the response from the chat agent based on the given query and topic classifier.\n",
    "\n",
    "        Args:\n",
    "            query (str): The user's query.\n",
    "            topic_classifier (TopicClassifier): The topic classifier used to classify the query.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the response generated by the chat agent.\n",
    "                  The response is stored under the key \"answer\".\n",
    "        \"\"\"\n",
    "        topic = topic_classifier.classify(query)\n",
    "        tool_name = None if topic == \"other\" else topic.capitalize() + \"Tool\"\n",
    "\n",
    "        try:\n",
    "            response = self.chat_agent.run(input=query, tool_name=tool_name) if tool_name else self.llm.generate(prompt=query)\n",
    "        except ValueError as e:\n",
    "            response = str(e)\n",
    "\n",
    "        return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        #input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        request = {'inputs': prompt,\n",
    "                    \"parameters\": { \"do_sample\": True,\n",
    "                                \"top_p\": 0.9,\n",
    "                                \"temperature\": 0.85,\n",
    "                                \"max_new_tokens\": 1024,\n",
    "                                \"stop\": [\"<|endoftext|>\", \"</s>\"],\n",
    "                                \"early_stopping\": True}}\n",
    "\n",
    "        input_str = json.dumps(request)\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        #return response_json[0][\"generated_text\"]\n",
    "    \n",
    "        if 'generated_text' in response_json[0]:\n",
    "            return response_json[0]['generated_text']\n",
    "        #response_json[0]['generated_text']\n",
    "        else:\n",
    "            # Return an empty string if the 'generated_text' key does not exist\n",
    "            return response_json\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize the ChatOpenAI model\n",
    "# llm = ChatOpenAI(\n",
    "#     openai_api_key=OPENAI_API_KEY,\n",
    "#     model='gpt-3.5-turbo',\n",
    "#     temperature=OPENAI_TEMPERATURE,\n",
    "# )\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "        endpoint_name=\"huggingface-pytorch-tgi-inference-2024-05-17-22-28-38-164\",\n",
    "        #credentials_profile_name=\"credentials-profile-name\",\n",
    "        region_name=\"us-east-1\",\n",
    "        model_kwargs={\"temperature\": 1e-10},\n",
    "        content_handler=content_handler,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"books\"\n"
     ]
    }
   ],
   "source": [
    "# from langchain import LLMChain\n",
    "# prompt_template = \"\"\"If the context is not relevant, \n",
    "#         please answer the question by using your own knowledge about the topic\n",
    "        \n",
    "        \n",
    "#         Question: {question}\n",
    "#         \"\"\"\n",
    "# PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# llm_chain = LLMChain(\n",
    "#      llm=llm,\n",
    "#      prompt=PROMPT\n",
    "#  )\n",
    "\n",
    "\n",
    "# llm_chain.run({\"Movie?\"})\n",
    "print(topic_classifier.classify(\"recommend me something I can read on kindle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/custom-miniconda/miniconda/envs/custom_python/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from vector_space import EmbeddingManager\n",
    "\n",
    "# Initialize components\n",
    "book_vector_store_path = \"data/book_vector_store\"\n",
    "movie_vector_store_path = \"data/movie_vector_store\"\n",
    "#embeddings_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#embeddings_model_name = \"intfloat/e5-base-v2\"\n",
    "embeddings_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "embeddings = EmbeddingManager(embeddings_model_name).get_embeddings()\n",
    "tool_manager = ToolManager(llm, movie_vector_store_path, book_vector_store_path,embeddings)\n",
    "topic_classifier = TopicClassifier(llm)\n",
    "chat_agent = ChatAgent(llm, tool_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Step 4: Testing and Iteration\n",
    "- Prototype Testing: Test the chatbot with a range of queries to ensure it retrieves relevant information and that LLM generates appropriate responses.\n",
    "- Iterative Improvement: Based on testing result, refine the retrieval strategy, prompt design, and response processing to improve the chatbot's accuracy and user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready to talk! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  movie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie\n",
      "AI: Could not parse LLM output: System: You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\n",
      "Human: TOOLS\n",
      "------\n",
      "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
      "\n",
      "> MoviesTool: Retrieve movie information.\n",
      "> BooksTool: Retrieve book information.\n",
      "\n",
      "RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you want the human to use a tool.\n",
      "Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": string, \\\\ The action to take. Must be one of MoviesTool, BooksTool\n",
      "    \"action_input\": string \\\\ The input to the action\n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": string \\\\ You should put what you want to return to use here\n",
      "}\n",
      "```\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
      "\n",
      "movie!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Human: TOOL RESPONSE: \n",
      "---------------------\n",
      "Invalid or incomplete response\n",
      "\n",
      "USER'S INPUT\n",
      "--------------------\n",
      "\n",
      "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:You: movie\n",
      "Chatbot: Error raised by inference endpoint: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (422) from primary with message \"{\"error\":\"Input validation error: `inputs` tokens + `max_new_tokens` must be <= 4096. Given: 5940 `inputs` tokens and 100 `max_new_tokens`\",\"error_type\":\"validation\"}\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-tgi-inference-2024-05-17-22-28-38-164 in account 905418217800 for more information.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot is ready to talk! Type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to exit.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/SageMaker/custom-miniconda/miniconda/envs/custom_python/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SageMaker/custom-miniconda/miniconda/envs/custom_python/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is ready to talk! Type 'quit' to exit.\")\n",
    "    \n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    response = chat_agent.get_response(user_input, topic_classifier)\n",
    "    print(f\"You: {user_input}\")\n",
    "    print(f\"Chatbot: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ChatAgent.__init__() missing 1 required positional argument: 'tool_manager'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mChatAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_response(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ChatAgent.__init__() missing 1 required positional argument: 'tool_manager'"
     ]
    }
   ],
   "source": [
    " ChatAgent(llm).get_response('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_python",
   "language": "python",
   "name": "custom_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
